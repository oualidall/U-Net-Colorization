# ğŸ¨ U-Net Colorization  
### *Automatic Colorization of Grayscale Vintage Photos using Deep Learning*  
**Author:** Oualid Allouch  
**TÃ©lÃ©com Physique Strasbourg â€” Data & AI Engineer**  
ğŸ“§ [oualid.allouch@etu.unistra.fr](mailto:oualid.allouch@etu.unistra.fr)  
ğŸ”— [LinkedIn â€“ Oualid Allouch]((https://www.linkedin.com/in/oualid-allouch-608b3738a/))

---

## ğŸ‡¬ğŸ‡§ Overview / ğŸ‡«ğŸ‡· PrÃ©sentation

This project implements a **U-Net-based deep neural network** trained on **ImageNet-64** for automatic colorization of grayscale or vintage photos.  
It combines **perceptual loss (VGG16 features)** with a custom **OldPhotoMaker degradation pipeline**, reproducing realistic aging (grain, vignette, scratches) to make the model robust to historical photos.

Ce projet met en Å“uvre un **rÃ©seau de neurones U-Net** entraÃ®nÃ© sur **ImageNet-64** pour la **colorisation automatique de photos anciennes en niveaux de gris**.  
Il associe une **perte perceptuelle (VGG16)** Ã  un **pipeline de dÃ©gradation personnalisÃ© (OldPhotoMaker)** simulant le vieillissement des clichÃ©s (grain, vignette, rayures).

---

## ğŸ§  Model Architecture / Architecture du ModÃ¨le

**U-Net Encoder-Decoder**
- Input: 1-channel grayscale image (64Ã—64)
- Encoder: stacked convolutions with downsampling
- Decoder: skip connections + upsampling to restore spatial color details
- Output: 3-channel colorized image

**Loss Function**
- `L_total = L1 + 0.1 Ã— L_perceptual(VGG16)`
- Perceptual term ensures semantically consistent colors

<p align="center">
  <img src="https://raw.githubusercontent.com/oualidall/U-Net-Colorization/main/docs/unet_architecture.png" alt="U-Net Diagram" width="650"/>
</p>

---

## ğŸ§© Training Pipeline / Pipeline dâ€™EntraÃ®nement

| Step | Description |
|------|--------------|
| 1ï¸âƒ£ | **OldPhotoMaker**: applies sepia tone, scratches, vignettes, and film grain to clean RGB images |
| 2ï¸âƒ£ | Convert degraded RGB â†’ grayscale input |
| 3ï¸âƒ£ | Train **U-Net** to predict the original RGB colors |
| 4ï¸âƒ£ | Optimize with **L1 + VGG perceptual loss** |
| 5ï¸âƒ£ | Evaluate with **SSIM** (structural similarity) and **L1 loss** |

<p align="center">
  <img src="https://raw.githubusercontent.com/oualidall/U-Net-Colorization/main/docs/pipeline_diagram.png" alt="Training Pipeline" width="750"/>
</p>

---

## ğŸ“Š Results / RÃ©sultats

**Quantitative Metrics (Validation):**
| Epoch | L1 â†“ | VGG â†“ | SSIM â†‘ |
|:------|:-----|:------|:------|
| 15 | 0.060 | 0.89 | **0.86** |

---

### ğŸ–¼ï¸ Visual Examples (Before â†’ Grayscale â†’ Predicted)

| Example | Link |
|----------|------|
| Dogs | [viz_class_300_test.png](outputs_examples/viz_class_300_test.png) |
| Castles | [viz_class_700_test.png](outputs_examples/viz_class_700_test.png) |
| Class #4 | [viz_class_0004_test.png](outputs_examples/viz_class_0004_test.png) |
| Class #15 | [viz_class_0015_test.png](outputs_examples/viz_class_0015_test.png) |
| Class #620 | [viz_class_0620_test.png](outputs_examples/viz_class_0620_test.png) |

*(Each triplet: Original â†’ Grayscale â†’ U-Net prediction)*

---

## âš™ï¸ Usage / Utilisation

### ğŸ”§ Installation

```bash
git clone https://github.com/oualidall/U-Net-Colorization.git
cd U-Net-Colorization
pip install -r requirements.txt
